# (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html),
# https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4
# https://github.com/cjhutto/vaderSentiment

import pandas as pd 
import nltk
from snorkel.labeling import PandasLFApplier, labeling_function, LFAnalysis
from snorkel.labeling.model import MajorityLabelVoter, LabelModel
from snorkel.labeling import filter_unlabeled_dataframe
from snorkel.utils import probs_to_preds
import numpy as np
import matplotlib.pyplot as plt 
from labeling_funcs.bbc_lfs import * 
from lgreg_utils import *
from mlflow import log_metric, log_param, log_artifacts
import mlflow
from datetime import datetime
import os 
from sklearn.metrics import precision_recall_fscore_support
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.feature_extraction import text
from sklearn.linear_model import LogisticRegressionCV
from lgreg_utils import read_data_from_config
from lgreg_config import *

import argparse
import warnings 

warnings.filterwarnings("ignore", category=DeprecationWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

parser = argparse.ArgumentParser()
parser.add_argument(dest='experiment_name', type=str, help="mlflow experiment name")
parser.add_argument(dest='config', type=str, help="'tweets_config' or 'bbc_config'")
args = parser.parse_args()

print(args)
print('parsing arguments..')
if args.config == 'tweets_config':
  config = tweets_config
elif args.config == 'bbc_config':
  config = bbc_config

print(f"setting up experiment: {args.experiment_name}")
mlflow.set_experiment(args.experiment_name)

lfs = config['lfs']

print('reading in data...')
X_train, y_train, X_dev, y_dev = read_data_from_config(config)

print('applying labelling functions to data...')
applier = PandasLFApplier(lfs=lfs)
L_train = applier.apply(df=X_train)
L_dev = applier.apply(df=X_dev)

print('fitting Label Model')
label_model = LabelModel(cardinality=config['cardinality'], verbose=True)
label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)
label_model_acc = label_model.score(L=L_dev, Y=y_dev, tie_break_policy="random")["accuracy"]
print(f'label model acc: {label_model_acc}')

print('fitting Majority Label Voter model')
majority_model = MajorityLabelVoter(cardinality=config['cardinality'])
# preds_train = majority_model.predict(L=L_train)
majority_acc = majority_model.score(L=L_dev, Y=np.array(y_dev).reshape(-1,1), tie_break_policy="random")["accuracy"]
print(f'majority_label_acc: {majority_acc}')

log_metric('majority_label_acc', majority_acc)
log_metric('label_model_acc', label_model_acc)

probs_train = label_model.predict_proba(L=L_train)
df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(
    X=X_train, y=probs_train, L=L_train
)

print('setting up Label Model')
stop_words = config['stop_words']
custom_stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)
# vectorizer = CountVectorizer(ngram_range=(1, 5))
vectorizer = TfidfVectorizer(stop_words=custom_stop_words).fit(X_train.text.tolist())
X_train_vectorized = vectorizer.transform(X_train.text.tolist()) 
X_train_filtered_vectorized = vectorizer.transform(df_train_filtered.text.tolist())  
preds_train_filtered = probs_to_preds(probs=probs_train_filtered)  # using weak labels generated by Label Model to train downstream classifier
X_dev = vectorizer.transform(X_dev.text.tolist())

print('training Logistic Regression model...')
log_param('model', 'log_reg_cv_10')
sklearn_model_weak_sup = LogisticRegressionCV(max_iter=500, cv=10, random_state=0, solver='liblinear').fit(X_train_filtered_vectorized, preds_train_filtered)
sklearn_model_full_sup = LogisticRegressionCV(max_iter=500, cv=10, random_state=0, solver='liblinear').fit(X_train_vectorized, y_train)

dev_weak_sup_accuracy = sklearn_model_weak_sup.score(X=X_dev, y=y_dev) * 100
dev_full_sup_accuracy = sklearn_model_full_sup.score(X=X_dev, y=y_dev) * 100

print_and_log_accuracies(dev_weak_sup_accuracy, dev_full_sup_accuracy)  
precision, recall, fscore, support = print_and_log_precision_recall_f1(sklearn_model_weak_sup, X_dev, y_dev)
precision, recall, fscore, support = print_and_log_precision_recall_f1(sklearn_model_full_sup, X_dev, y_dev)

