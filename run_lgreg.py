# (https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html),
# https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4
# https://github.com/cjhutto/vaderSentiment

import pandas as pd 
import nltk
from snorkel.labeling import PandasLFApplier, labeling_function, LFAnalysis
from snorkel.labeling.model import MajorityLabelVoter, LabelModel
from snorkel.labeling import filter_unlabeled_dataframe
from snorkel.utils import probs_to_preds
import numpy as np
import matplotlib.pyplot as plt 
from labeling_funcs.bbc_lfs import * 
from run_lgreg_utils import *
from plotting_funcs import plot_label_frequency, plot_probabilities_histogram
from mlflow import log_metric, log_param, log_artifacts
import mlflow
from datetime import datetime
import os 
from sklearn.metrics import precision_recall_fscore_support
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.feature_extraction import text

mlflow.set_experiment('bbc_bigrams')

# lfs = [lf_contains_tech_terms, lf_contains_business_terms, lf_contains_sport_terms,
#         lf_contains_entertainment_terms, lf_contains_politics_terms]

lfs = [lf_contains_tech_terms, lf_contains_business_terms, lf_contains_sport_terms, 
        lf_contains_entertainment_terms, lf_contains_politics_terms]

print('reading in data...')
X_train = pd.read_csv('data/processed/bbc_x_train.csv')
y_train = pd.read_csv('data/processed/bbc_y_train.csv')

X_dev = pd.read_csv('data/processed/bbc_x_dev.csv')
y_dev = pd.read_csv('data/processed/bbc_y_dev.csv')

print('applying labelling functions to data...')
applier = PandasLFApplier(lfs=lfs)
L_train = applier.apply(df=X_train)
L_dev = applier.apply(df=X_dev)

print('fitting Label Model')
label_model = LabelModel(cardinality=5, verbose=True)
label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)
label_model_acc = label_model.score(L=L_dev, Y=y_dev, tie_break_policy="random")["accuracy"]
print(f'label model acc: {label_model_acc}')

print('fitting Majority Label Voter model')
majority_model = MajorityLabelVoter(cardinality=5)
# preds_train = majority_model.predict(L=L_train)
majority_acc = majority_model.score(L=L_dev, Y=np.array(y_dev).reshape(-1,1), tie_break_policy="random")["accuracy"]
print(f'majority_label_acc: {majority_acc}')

log_metric('majority_label_acc', majority_acc)
log_metric('label_model_acc', label_model_acc)

probs_train = label_model.predict_proba(L=L_train)
df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(
    X=X_train, y=probs_train, L=L_train
)

print('setting up Label Model')
# airline_stop_words = ['united', 'usairways', 'southwestair', 'americanair', 'jetblue', 'virginamerica'), 'flight']
# custom_stop_words = text.ENGLISH_STOP_WORDS.union(airline_stop_words)
bbc_stop_words = ['said', 'people', 'new', 'mr', 'quarter', '2004', 'month', 'year', 'ago', 'old', 'don', 'know',
                    'recent', 'months']
custom_stop_words = text.ENGLISH_STOP_WORDS.union(bbc_stop_words)
# vectorizer = CountVectorizer(ngram_range=(1, 5))
vectorizer_filtered = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2,2))
vectorizer_unfiltered = TfidfVectorizer(stop_words=custom_stop_words, ngram_range=(2,2))
X_train_filtered = vectorizer_filtered.fit_transform(df_train_filtered.text.tolist())  
X_train = vectorizer_unfiltered.fit_transform(X_train.text.tolist()) 
preds_train_filtered = probs_to_preds(probs=probs_train_filtered)  # using weak labels generated by Label Model to train downstream classifier
X_dev_unfiltered = vectorizer_unfiltered.transform(X_dev.text.tolist())
X_dev_filtered = vectorizer_filtered.transform(X_dev.text.tolist())

print('training Logistic Regression model...')
from sklearn.linear_model import LogisticRegressionCV
log_param('model', 'log_reg_cv_10')
sklearn_model_weak_sup = LogisticRegressionCV(max_iter=500, cv=10, random_state=0, solver='liblinear').fit(X_train_filtered, preds_train_filtered)
sklearn_model_full_sup = LogisticRegressionCV(max_iter=500, cv=10, random_state=0, solver='liblinear').fit(X_train, y_train)
# cv_weak = sklearn_model_weak_sup.score(X_train_filtered, y_train)
# cv_sup = sklearn_model_full_sup.score(X_train, y_train)

dev_weak_sup_accuracy = sklearn_model_weak_sup.score(X=X_dev_filtered, y=y_dev) * 100
dev_full_sup_accuracy = sklearn_model_full_sup.score(X=X_dev_unfiltered, y=y_dev) * 100

print_and_log_accuracies(dev_weak_sup_accuracy, dev_full_sup_accuracy)   # cv_weak, cv_sup, 
precision, recall, fscore, support = get_and_log_precision_recall_f1(sklearn_model_weak_sup, X_dev, y_dev)


metrics = pd.DataFrame({'precision':precision, 'recall':recall, 'fscore':fscore, 'support': support})
metrics_csv_name = datetime.now().strftime('%Y%m%d%M') + 'metrics.csv'
metrics.to_csv('outputs/' + metrics_csv_name)
print('overall metrics saved to outputs/csv_name')

print('plotting summary graphs of labeling functions')
# plot_probabilities_histogram(probs_train[:, BUSINESS])
plot_label_frequency(L_train)

lf_summary = LFAnalysis(L=L_train, lfs=lfs).lf_summary()
csv_name = datetime.now().strftime('%Y%m%d%M') + 'lf_summary.csv'
lf_summary.to_csv('outputs/' + csv_name)
print(f'labelling functions summary csv saved to outputs/{csv_name}')
print(lf_summary)

log_artifacts("outputs")
